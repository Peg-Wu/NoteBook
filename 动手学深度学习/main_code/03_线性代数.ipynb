{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import torch"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 对称矩阵$A$等于其转置：$A = A^T$"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[True, True, True],\n        [True, True, True],\n        [True, True, True]])"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B = torch.tensor([[1, 2, 3],\n",
    "                  [2, 0, 4],\n",
    "                  [3, 4, 5]])\n",
    "B == B.T"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([[1., 1., 1., 1., 1.],\n         [1., 1., 1., 1., 1.],\n         [1., 1., 1., 1., 1.],\n         [1., 1., 1., 1., 1.]]),\n tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n         1., 1.]))"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 拓展：关于reshape\n",
    "A = torch.arange(20, dtype=torch.float32)\n",
    "A_reshape = A.reshape((4, 5))\n",
    "A_reshape[:] = 1.\n",
    "A_reshape, A  # A_reshape只是A的一个view，修改A_reshape的值，A也会变化"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## A.clone() 的应用"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "A = torch.tensor([1.0])\n",
    "B = A\n",
    "print(id(A) == id(B))  # 不会给B分配新的内存\n",
    "\n",
    "C = A.clone()\n",
    "print(id(A) == id(C))  # 给C分配新的内存"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 张量的元素和"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "(torch.Size([2, 5, 4]), tensor(780.))"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.arange(20*2, dtype=torch.float32).reshape((2, 5, 4))\n",
    "A.shape, A.sum()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([[20., 22., 24., 26.],\n         [28., 30., 32., 34.],\n         [36., 38., 40., 42.],\n         [44., 46., 48., 50.],\n         [52., 54., 56., 58.]]),\n torch.Size([5, 4]),\n torch.Size([1, 5, 4]))"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# axis = 0\n",
    "A_sum_axis0 = A.sum(axis=0)\n",
    "A_sum_axis0_keep = A.sum(axis=0, keepdims=True)  # 求和后不把第0个维度丢掉，对后续做广播机制有好处！\n",
    "A_sum_axis0, A_sum_axis0.shape, A_sum_axis0_keep.shape  # 相当于把两个5x4的tensor按元素相加，第0个维度消失"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([[ 40.,  45.,  50.,  55.],\n         [140., 145., 150., 155.]]),\n torch.Size([2, 4]))"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# axis = 1\n",
    "A_sum_axis1 = A.sum(axis=1)\n",
    "A_sum_axis1, A_sum_axis1.shape  # 相当于对每一个5x4的tensor操作，每一列所有元素相加，第1个维度消失"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([[  6.,  22.,  38.,  54.,  70.],\n         [ 86., 102., 118., 134., 150.]]),\n torch.Size([2, 5]))"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# axis = 2\n",
    "A_sum_axis2 = A.sum(axis=2)\n",
    "A_sum_axis2, A_sum_axis2.shape  # 相当于对每一个5x4的tensor操作，每一行所有元素相加，第2个维度消失"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4])\n"
     ]
    },
    {
     "data": {
      "text/plain": "tensor([True, True, True, True])"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# axis = [0, 1]\n",
    "print(A.sum(axis=[0, 1]).shape)  # 第0个维度和第1个维度均消失\n",
    "A.sum(axis=0).sum(axis=0) == A.sum(axis=[0, 1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 求均值、累加、点积、矩阵x向量、矩阵x矩阵、范数"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor(19.5000), tensor(19.5000))"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.mean(), A.sum() / A.numel()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([[10., 11., 12., 13.],\n         [14., 15., 16., 17.],\n         [18., 19., 20., 21.],\n         [22., 23., 24., 25.],\n         [26., 27., 28., 29.]]),\n tensor([[10., 11., 12., 13.],\n         [14., 15., 16., 17.],\n         [18., 19., 20., 21.],\n         [22., 23., 24., 25.],\n         [26., 27., 28., 29.]]))"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 按特定的维度求均值\n",
    "A.mean(axis=0), A.sum(axis=0) / A.shape[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[  0.,   1.,   2.,   3.],\n         [  4.,   6.,   8.,  10.],\n         [ 12.,  15.,  18.,  21.],\n         [ 24.,  28.,  32.,  36.],\n         [ 40.,  45.,  50.,  55.]],\n\n        [[ 20.,  21.,  22.,  23.],\n         [ 44.,  46.,  48.,  50.],\n         [ 72.,  75.,  78.,  81.],\n         [104., 108., 112., 116.],\n         [140., 145., 150., 155.]]])"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 累加\n",
    "A.cumsum(axis=1)\n",
    "\n",
    "# 点积：torch.dot(a, b)\n",
    "# 矩阵x向量：torch.mv(A, b)\n",
    "# 矩阵x矩阵：torch.mm(A, B)\n",
    "# 范数L2：torch.norm(v)，对于矩阵求的是Frobenius norm范数（F范数）\n",
    "# 范数L1：torch.abs(v).sum()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}