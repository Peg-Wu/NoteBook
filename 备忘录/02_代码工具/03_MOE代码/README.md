# é¢„æµ‹äººç±»RNAä¸­2'-O-ç”²åŸºåŒ–(2OM)ä½ç‚¹

- åŸºäºMixture Of Experts(MOE)æ¨¡å‹
  - Expertä¸“å®¶æ¨¡å‹ï¼Œ**æ¨¡å‹å¾…å®Œå–„ä¸­...**
  - Gateé—¨æ§æ¨¡å‹ï¼Œ**æ¨¡å‹å¾…å®Œå–„ä¸­...**
  - è¯¥æ¨¡å‹åŒ…å«4ä¸ªExpertsï¼Œæ¯ä¸ªExpertæ¨¡å‹æ¶æ„ç›®å‰æ˜¯ä¸€è‡´çš„ï¼Œ**è¿™4ä¸ªä¸“å®¶åˆ†åˆ«å¤„ç†A2OMã€G2OMã€C2OMå’ŒU2OMæ•°æ®**
- è®­ç»ƒè¯·è¿è¡Œ`Train.py`
- æµ‹è¯•è¯·è¿è¡Œ`Test.py`
- æœ¬é¡¹ç›®æä¾›äº†MOEæ¨¡å‹è®­ç»ƒå¯è§†åŒ–ï¼Œåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œä¼šç”Ÿæˆ`./logs`æ–‡ä»¶ï¼Œè¯·ä½¿ç”¨`Tensorboard`æŸ¥çœ‹ï¼

## ğŸ¨è®­ç»ƒç­–ç•¥è¯´æ˜

1. ä¸“å®¶æ¨¡å‹åœ¨è®­ç»ƒXä¸ªepochåï¼Œå¦‚æœ`è®­ç»ƒæŸå¤±`æ²¡æœ‰é™ä½ï¼Œåˆ™æå‰åœæ­¢è®­ç»ƒ
2. MOEæ¨¡å‹åœ¨è®­ç»ƒXä¸ªepochåï¼Œå¦‚æœ`éªŒè¯å‡†ç¡®ç‡`æ²¡æœ‰å‡é«˜ï¼Œåˆ™æå‰åœæ­¢è®­ç»ƒ
3. ç¬¬ä¸€é˜¶æ®µï¼šè®­ç»ƒä¸“å®¶æ¨¡å‹ï¼Œ`ä¸“å®¶æ¨¡å‹æ²¡æœ‰éªŒè¯é›†`ï¼Œåªè¿›è¡Œè®­ç»ƒï¼Œæ ¹æ®è®­ç»ƒæŸå¤±éšæ—¶ç»ˆæ­¢
4. ç¬¬äºŒé˜¶æ®µï¼šè®­ç»ƒMOEæ¨¡å‹ï¼Œ`MOEæ¨¡å‹æœ‰éªŒè¯é›†`ï¼Œå¹¶è®°å½•äº†Accuracyã€MCCã€Precisionã€F1ã€Spã€Snç­‰æŒ‡æ ‡

## æµ‹è¯•é›†æ³›åŒ–æƒ…å†µ

- Model1: Expertæ¨¡å‹åŸºäº**CNN-Transformer**ï¼Œåºåˆ—é€šè¿‡**OneHot**ç¼–ç 
  - ç»è¿‡å®éªŒï¼ŒWord2Vecæ•ˆæœåœ¨éªŒè¯é›†ä¸Šå·®ä¸å¤šï¼Œä½†æ˜¯æ³›åŒ–æ€§èƒ½è¾ƒå·®ï¼Œä¸”nn.Embedding()æå¤§å¢åŠ äº†è®­ç»ƒæ—¶é—´


```python
"""
MOE:
Accuracy: 0.8068306008724507
Precision: 0.837237236734392
F1: 0.7977110155085233
MCC: 0.6161709040873619
Sn: 0.7617486334635253
Sp: 0.8519125678404849
"""

import torch
from torch import nn

def conv1d_k1_block(in_channels, out_channels, padding=0, stride=1):
    return nn.Sequential(nn.Conv1d(in_channels, out_channels, 1, stride, padding),
                         nn.BatchNorm1d(out_channels), nn.ReLU())

class CancelOut(nn.Module):
    '''
    CancelOut Layer
    x - an input data (vector, matrix, tensor)
    '''
    def __init__(self, inp, *kargs, **kwargs):
        super(CancelOut, self).__init__()
        self.weights = nn.Parameter(torch.zeros(inp, requires_grad=True) + 4)

    def forward(self, x):
        return (x * torch.sigmoid(self.weights.float()))

class Expert(nn.Module):
    def __init__(self, in_channels):
        super(Expert, self).__init__()
        self.conv3 = nn.Sequential(nn.Conv1d(in_channels, 64, 3, 1, 1), nn.BatchNorm1d(64), nn.ReLU(),
                                   conv1d_k1_block(64, 32))
        self.conv5 = nn.Sequential(nn.Conv1d(in_channels, 64, 5, 1, 2), nn.BatchNorm1d(64), nn.ReLU(),
                                   conv1d_k1_block(64, 32))
        self.conv7 = nn.Sequential(nn.Conv1d(in_channels, 64, 7, 1, 3), nn.BatchNorm1d(64), nn.ReLU(),
                                   conv1d_k1_block(64, 32))
        self.conv9 = nn.Sequential(nn.Conv1d(in_channels, 64, 9, 1, 4), nn.BatchNorm1d(64), nn.ReLU(),
                                   conv1d_k1_block(64, 32))
        self.tf_encoder_layer = nn.TransformerEncoderLayer(128, 8, batch_first=True)
        self.tf_encoder = nn.TransformerEncoder(self.tf_encoder_layer, 3)
        self.dense = nn.Sequential(nn.Linear(128, 32), nn.BatchNorm1d(32), nn.ReLU(), nn.Linear(32, 2))

    def forward(self, X):
        X = X.permute(0, 2, 1)  # (batch, 4, 41)
        # å°†one_hotä½œä¸ºç‰¹å¾ç»´è¿›è¡Œå·ç§¯
        X = torch.cat([self.conv3(X), self.conv5(X), self.conv7(X), self.conv9(X)], dim=1)  # (batch, 128, 41)
        X = X.permute(0, 2, 1)  # (batch_size, 41, 128)
        X = self.tf_encoder(X)
        # Mean pooling
        X = torch.mean(X, dim=1)
        X = self.dense(X)
        return X

class Gate(nn.Module):
    def __init__(self, num_experts=4):
        super(Gate, self).__init__()
        self.num_experts = num_experts
        self.dense = nn.Sequential(
            CancelOut(41),
            nn.Linear(41, 16),
            nn.ReLU(),
            nn.Dropout(0.5),
            nn.Linear(16, 4),
            nn.Softmax(dim=1))

    def forward(self, X):
        X = X.mean(dim=-1)
        return self.dense(X)

class MOE(nn.Module):
    def __init__(self, trained_experts: list):
        super(MOE, self).__init__()
        self.experts = nn.ModuleList(trained_experts)
        self.num_experts = len(trained_experts)
        self.gate = Gate(num_experts=4)

    def forward(self, X):
        weights = self.gate(X)
        # åä¸¤ç»´ï¼šæ¯ä¸€åˆ—æ˜¯ä¸€ä¸ªä¸“å®¶çš„é¢„æµ‹ç»“æœ
        outputs = torch.stack([expert(X) for expert in self.experts], dim=2)
        weights = weights.unsqueeze(1).expand_as(outputs)
        return torch.sum(outputs * weights, dim=2)
```
